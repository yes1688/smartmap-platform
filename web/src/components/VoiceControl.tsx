import { Component, createSignal, onCleanup } from 'solid-js';
import { gameStore, setCurrentPlayer } from '@/stores/gameStore';

interface VoiceControlProps {
  onVoiceCommand: (text: string) => void;
}

interface BrowserInfo {
  name: string;
  mimeType: string;
  ext: string;
  isSupported: boolean;
  webCodecsSupported?: boolean;
  recordingMethod?: 'webcodecs' | 'mediarecorder';
}

interface WebCodecsInfo {
  audioEncoder: boolean;
  audioDecoder: boolean;
  opusSupported: boolean;
  fullSupported: boolean;
}

const VoiceControl: Component<VoiceControlProps> = (props) => {
  const [isRecording, setIsRecording] = createSignal(false);
  const [isProcessing, setIsProcessing] = createSignal(false);
  const [lastTranscription, setLastTranscription] = createSignal('');
  const [error, setError] = createSignal('');

  let mediaRecorder: MediaRecorder | null = null;
  let audioEncoder: AudioEncoder | null = null;
  let audioChunks: Blob[] = [];
  let audioPackets: Uint8Array[] = [];
  let recordingStartTime: number = 0;

  // WebCodecs æ”¯æ´æª¢æ¸¬ - ä¾†è‡ª Speech Ear
  const detectWebCodecsSupport = (): WebCodecsInfo => {
    const hasAudioEncoder = typeof AudioEncoder !== 'undefined';
    const hasAudioDecoder = typeof AudioDecoder !== 'undefined';

    let opusSupported = false;
    if (hasAudioEncoder) {
      try {
        const testConfig = {
          codec: 'opus',
          sampleRate: 48000,
          numberOfChannels: 1,
          bitrate: 128000
        };
        // ç°¡åŒ–æª¢æ¸¬é‚è¼¯ï¼Œç›´æ¥å˜—è©¦å‰µå»ºç·¨ç¢¼å™¨
        try {
          const testEncoder = new AudioEncoder({
            output: () => {},
            error: () => {}
          });
          testEncoder.configure(testConfig);
          testEncoder.close();
          opusSupported = true;
        } catch {
          opusSupported = false;
        }
      } catch (e) {
        console.warn('WebCodecs OPUS æ”¯æ´æª¢æ¸¬å¤±æ•—:', e);
        opusSupported = false;
      }
    }

    const fullSupported = hasAudioEncoder && hasAudioDecoder && opusSupported;

    return {
      audioEncoder: hasAudioEncoder,
      audioDecoder: hasAudioDecoder,
      opusSupported: opusSupported,
      fullSupported: fullSupported
    };
  };

  // æª¢æ¸¬ç€è¦½å™¨å’Œæ”¯æ´çš„æ ¼å¼ - ä¾†è‡ª Speech Ear å¯¦è­‰å¯¦ç¾
  const detectBrowser = (): BrowserInfo => {
    const ua = navigator.userAgent;
    const webCodecs = detectWebCodecsSupport();

    if (ua.includes('Chrome') && !ua.includes('Edge')) {
      const mimeType = 'audio/webm;codecs=opus';
      return {
        name: 'Chrome',
        mimeType,
        ext: 'webm',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Edge')) {
      const mimeType = 'audio/webm;codecs=opus';
      return {
        name: 'Edge',
        mimeType,
        ext: 'webm',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Firefox')) {
      const mimeType = 'audio/ogg;codecs=opus';
      return {
        name: 'Firefox',
        mimeType,
        ext: 'ogg',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Safari')) {
      const mimeType = 'audio/mp4';
      return {
        name: 'Safari',
        mimeType,
        ext: 'mp4',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    }

    // æœªçŸ¥ç€è¦½å™¨ï¼Œå˜—è©¦é€šç”¨æ ¼å¼
    const fallbackMime = 'audio/webm';
    return {
      name: 'Unknown',
      mimeType: fallbackMime,
      ext: 'webm',
      isSupported: MediaRecorder.isTypeSupported(fallbackMime),
      webCodecsSupported: webCodecs.fullSupported,
      recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
    };
  };

  // é–‹å§‹éŒ„éŸ³
  const startRecording = async () => {
    try {
      setError('');

      // ä½¿ç”¨ Speech Ear çš„éŸ³é »é…ç½®
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      // è¨ºæ–·ï¼šæª¢æŸ¥ç€è¦½å™¨å¯¦éš›æä¾›çš„éŸ³é »é…ç½®
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        const trackSettings = audioTrack.getSettings();
        console.log('ğŸ” ç€è¦½å™¨å¯¦éš›éŸ³é »é…ç½®:', trackSettings);
        console.log(`  - å¯¦éš›æ¡æ¨£ç‡: ${trackSettings.sampleRate}Hz`);
        console.log(`  - å¯¦éš›è²é“æ•¸: ${trackSettings.channelCount}`);
        console.log(`  - é…ç½®åŒ¹é…: ${trackSettings.sampleRate === 48000 ? 'âœ… ä¸€è‡´' : 'âš ï¸ ä¸åŒ¹é…'}`);
      }

      // ä½¿ç”¨ Speech Ear çš„ç€è¦½å™¨æª¢æ¸¬é‚è¼¯
      const browser = detectBrowser();
      console.log('ğŸŒ æª¢æ¸¬åˆ°ç€è¦½å™¨:', browser);
      console.log('ğŸš€ WebCodecs æ”¯æ´:', browser.webCodecsSupported);
      console.log('ğŸ¤ éŒ„éŸ³æ–¹å¼:', browser.recordingMethod);

      if (!browser.isSupported) {
        throw new Error(`ç€è¦½å™¨ ${browser.name} ä¸æ”¯æ´éŸ³é »æ ¼å¼ ${browser.mimeType}`);
      }

      // æ™ºèƒ½éŒ„éŸ³æ–¹å¼é¸æ“‡
      if (browser.recordingMethod === 'webcodecs' && browser.webCodecsSupported) {
        console.log('ğŸš€ ä½¿ç”¨ WebCodecs ç¡¬é«”åŠ é€ŸéŒ„éŸ³');
        await startWebCodecsRecording(stream);
      } else {
        console.log('ğŸ“¼ ä½¿ç”¨ MediaRecorder ç›¸å®¹æ¨¡å¼éŒ„éŸ³');
        await startMediaRecorderRecording(stream);
      }

      recordingStartTime = Date.now();

    } catch (err) {
      console.error('âŒ éŒ„éŸ³å¤±æ•—:', err);
      setError('ç„¡æ³•å­˜å–éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­å®š');
    }
  };

  // WebCodecs éŒ„éŸ³å¯¦ç¾
  const startWebCodecsRecording = async (stream: MediaStream) => {
    console.log('ğŸš€ å•Ÿå‹• WebCodecs ç¡¬é«”åŠ é€ŸéŒ„éŸ³');

    audioPackets = [];

    try {
      audioEncoder = new AudioEncoder({
        output: (chunk, metadata) => {
          console.log(`ğŸµ WebCodecs ç¨ç«‹åŒ…è¼¸å‡º: ${chunk.byteLength} bytes`);
          const packetData = new Uint8Array(chunk.byteLength);
          chunk.copyTo(packetData);
          audioPackets.push(packetData);
          console.log(`ğŸ“¦ æ”¶é›†åˆ° OPUS åŒ… ${audioPackets.length}: ${packetData.length} bytes`);
        },
        error: (error) => {
          console.error('ğŸš¨ WebCodecs ç·¨ç¢¼éŒ¯èª¤:', error);
          setError(`WebCodecs ç·¨ç¢¼å¤±æ•—: ${error.message}`);
        }
      });

      const optimizedEncoderConfig = {
        codec: 'opus',
        sampleRate: 48000,
        numberOfChannels: 1,
        bitrate: 96000,
      };

      audioEncoder.configure(optimizedEncoderConfig);

      const track = stream.getAudioTracks()[0];
      const processor = new MediaStreamTrackProcessor({ track });
      const reader = processor.readable.getReader();

      const processAudioFrames = async () => {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          if (audioEncoder && audioEncoder.state === 'configured') {
            try {
              audioEncoder.encode(value);
            } catch (err) {
              console.error('ğŸš¨ éŸ³é »å¹€ç·¨ç¢¼å¤±æ•—:', err);
            }
          }
          value.close();
        }
      };

      processAudioFrames().catch(err => {
        console.error('ğŸš¨ éŸ³é »è™•ç†æµç¨‹éŒ¯èª¤:', err);
        setError(`WebCodecs éŸ³é »è™•ç†å¤±æ•—: ${err.message}`);
      });

      setIsRecording(true);
      console.log('âœ… WebCodecs éŒ„éŸ³å·²å•Ÿå‹•');

    } catch (error) {
      console.error('ğŸš¨ WebCodecs åˆå§‹åŒ–å¤±æ•—:', error);
      setError(`WebCodecs åˆå§‹åŒ–å¤±æ•—: ${error.message}`);
    }
  };

  // MediaRecorder éŒ„éŸ³å¯¦ç¾
  const startMediaRecorderRecording = async (stream: MediaStream) => {
    console.log('ğŸ“¼ å•Ÿå‹• MediaRecorder ç›¸å®¹æ¨¡å¼éŒ„éŸ³');

    const browser = detectBrowser();
    const mimeType = browser.mimeType;

    mediaRecorder = new MediaRecorder(stream, {
      mimeType,
      audioBitsPerSecond: 64000
    });

    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: mimeType });

      console.log(`âœ… MediaRecorder éŒ„éŸ³å®Œæˆ - æ ¼å¼: ${mimeType}, å¤§å°: ${audioBlob.size} bytes`);

      stream.getTracks().forEach(track => track.stop());
      await transcribeAudio(audioBlob);
    };

    mediaRecorder.start();
    setIsRecording(true);
    console.log('âœ… MediaRecorder éŒ„éŸ³å·²å•Ÿå‹•');
  };

  // åœæ­¢éŒ„éŸ³
  const stopRecording = () => {
    const browser = detectBrowser();

    if (browser.recordingMethod === 'webcodecs' && audioEncoder) {
      console.log('ğŸ›‘ åœæ­¢ WebCodecs éŒ„éŸ³');
      try {
        audioEncoder.flush();
        audioEncoder.close();
        audioEncoder = null;

        if (audioPackets.length > 0) {
          const packetsData = {
            format: 'webcodecs_opus_packets',
            packet_count: audioPackets.length,
            packets: audioPackets.map(packet => Array.from(packet))
          };

          const jsonBlob = new Blob([JSON.stringify(packetsData)], { type: 'application/json' });

          console.log(`âœ… WebCodecs éŒ„éŸ³å®Œæˆ - æ ¼å¼: ç¨ç«‹åŒ…æ¨¡å¼, åŒ…æ•¸é‡: ${audioPackets.length}, JSON å¤§å°: ${jsonBlob.size} bytes`);

          transcribeAudio(jsonBlob);
        } else {
          console.warn('âš ï¸ WebCodecs éŒ„éŸ³æ²’æœ‰æ”¶é›†åˆ°ç¨ç«‹åŒ…');
          setError('éŒ„éŸ³å¤±æ•—ï¼šæ²’æœ‰æ”¶é›†åˆ°éŸ³é »åŒ…æ•¸æ“š');
        }

      } catch (error) {
        console.error('ğŸš¨ WebCodecs åœæ­¢éŒ„éŸ³æ™‚å‡ºéŒ¯:', error);
        setError('åœæ­¢éŒ„éŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤');
      }

    } else if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ›‘ åœæ­¢ MediaRecorder éŒ„éŸ³');
      mediaRecorder.stop();
    }

    setIsRecording(false);
    setIsProcessing(true);
  };

  // èªéŸ³è½‰æ–‡å­—
  const transcribeAudio = async (audioBlob: Blob) => {
    console.log('ğŸ¯ transcribeAudio å‡½æ•¸è¢«å‘¼å«');
    try {
      // æª¢æŸ¥éŒ„éŸ³æ™‚é–“å’Œå¤§å°
      const recordingDuration = Date.now() - recordingStartTime;
      console.log('â±ï¸ éŒ„éŸ³æ™‚é•·:', recordingDuration, 'ms');

      if (recordingDuration < 500) {
        setError('éŒ„éŸ³æ™‚é–“å¤ªçŸ­ï¼Œè«‹è‡³å°‘èªªè©± 0.5 ç§’');
        return;
      }

      if (audioBlob.size < 100) {
        setError('éŸ³é »æ•¸æ“šå¤ªå°ï¼Œè«‹é‡æ–°éŒ„éŸ³');
        return;
      }

      const formData = new FormData();
      const browser = detectBrowser();

      // æ™ºèƒ½ä¸Šå‚³æ ¼å¼é¸æ“‡
      if (audioBlob.type === 'application/json' && browser.recordingMethod === 'webcodecs') {
        // WebCodecs ç¨ç«‹åŒ…æ¨¡å¼
        const fileName = 'webcodecs-packets.json';
        formData.append('audio_packets', audioBlob, fileName);

        console.log(`ğŸš€ WebCodecs ç¨ç«‹åŒ…ä¸Šå‚³ - æª”æ¡ˆ: ${fileName}, MIME: ${audioBlob.type}, å¤§å°: ${audioBlob.size} bytes`);
        console.log('ğŸ¯ ä½¿ç”¨çµ±ä¸€ç«¯é»ï¼ŒJSON æ ¼å¼è‡ªå‹•æª¢æ¸¬');
      } else {
        // MediaRecorder å‚³çµ±æ ¼å¼
        const fileName = `recording.${browser.ext}`;
        formData.append('audio', audioBlob, fileName);

        console.log(`ğŸ“¼ MediaRecorder ä¸Šå‚³ - æª”æ¡ˆ: ${fileName}, MIME: ${audioBlob.type}, ç€è¦½å™¨: ${browser.name}`);
        console.log('ğŸ¯ ä½¿ç”¨çµ±ä¸€ç«¯é»ï¼ŒäºŒé€²åˆ¶æ ¼å¼è‡ªå‹•æª¢æ¸¬');
      }

      console.log('ğŸ”„ å‚³é€éŸ³é »åˆ° Speech Ear API...');
      console.log('ğŸ“ éŸ³é »å¤§å°:', (audioBlob.size / 1024).toFixed(2), 'KB');
      console.log('ğŸµ éŸ³é »é¡å‹:', audioBlob.type);
      console.log('ğŸ“Š éŸ³é » chunks æ•¸é‡:', audioChunks.length);

      const speechEarUrl = import.meta.env.VITE_SPEECH_EAR_URL || 'http://localhost:3001';
      console.log('ğŸŒ Speech Ear URL:', speechEarUrl);
      console.log('ğŸ”§ Environment variable:', import.meta.env.VITE_SPEECH_EAR_URL);
      const response = await fetch(`${speechEarUrl}/upload`, {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.log('ğŸš¨ Speech Ear API éŒ¯èª¤å›æ‡‰:', errorText);
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('âœ… èªéŸ³è½‰æ–‡å­—çµæœ:', result);

      // æ”¯æ´å¤šç¨®å›æ‡‰æ ¼å¼ (Care Voice å’Œ Speech Ear)
      const transcription = result.transcript || result.full_transcript || result.text;
      if (transcription && transcription.trim()) {
        const finalTranscription = transcription.trim();
        setLastTranscription(finalTranscription);

        // å‚³é€èªéŸ³æŒ‡ä»¤
        props.onVoiceCommand(finalTranscription);

        console.log('ğŸ¯ èªéŸ³æŒ‡ä»¤:', finalTranscription);
        console.log('âš¡ è™•ç†æ™‚é–“:', result.processing_time_ms, 'ms');
        console.log('ğŸ¯ ä¿¡å¿ƒåº¦:', result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'æœªçŸ¥');
        console.log('ğŸ¤– ä½¿ç”¨æ¨¡å‹:', result.model_used);
        if (result.summary) console.log('ğŸ“ æ‘˜è¦:', result.summary);
      } else {
        setError('æœªèƒ½è­˜åˆ¥èªéŸ³å…§å®¹ï¼Œè«‹é‡è©¦');
      }

    } catch (err) {
      console.error('âŒ èªéŸ³è½‰æ–‡å­—å¤±æ•—:', err);
      setError('èªéŸ³è™•ç†å¤±æ•—ï¼š' + (err as Error).message);
    } finally {
      setIsProcessing(false);
    }
  };

  // æŒ‰ä½éŒ„éŸ³ï¼Œé¬†é–‹åœæ­¢
  const handleMouseDown = (e: MouseEvent) => {
    e.preventDefault();
    console.log('ğŸ–±ï¸ æŒ‰ä¸‹æŒ‰éˆ•ï¼Œç•¶å‰ç‹€æ…‹ - éŒ„éŸ³:', isRecording(), 'è™•ç†:', isProcessing());
    if (!isRecording() && !isProcessing()) {
      console.log('ğŸ¤ é–‹å§‹éŒ„éŸ³æµç¨‹...');
      startRecording();
      // æ·»åŠ å…¨åŸŸç›£è½å™¨ç¢ºä¿æ•ç²é¬†é–‹äº‹ä»¶
      const handleGlobalMouseUp = () => {
        console.log('ğŸ–±ï¸ å…¨åŸŸé¬†é–‹äº‹ä»¶ï¼Œç•¶å‰éŒ„éŸ³ç‹€æ…‹:', isRecording());
        if (isRecording()) {
          console.log('ğŸ›‘ åœæ­¢éŒ„éŸ³æµç¨‹...');
          stopRecording();
        }
        document.removeEventListener('mouseup', handleGlobalMouseUp);
        document.removeEventListener('touchend', handleGlobalMouseUp);
      };
      document.addEventListener('mouseup', handleGlobalMouseUp);
      document.addEventListener('touchend', handleGlobalMouseUp);
    }
  };

  const handleMouseUp = () => {
    if (isRecording()) {
      stopRecording();
    }
  };

  // æ¸…ç†è³‡æº
  onCleanup(() => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
  });

  return (
    <div class="fixed bottom-4 right-4 z-50">
      {/* èªéŸ³æŒ‰éˆ• */}
      <div class="flex flex-col items-center gap-2">

        {/* ä¸»è¦éŒ„éŸ³æŒ‰éˆ• */}
        <button
          onMouseDown={handleMouseDown}
          onMouseUp={handleMouseUp}
          onTouchStart={handleMouseDown}
          onTouchEnd={handleMouseUp}
          disabled={isProcessing()}
          class={`
            w-16 h-16 rounded-full shadow-lg border-4 transition-all duration-200
            flex items-center justify-center
            ${isRecording()
              ? 'bg-red-500 border-red-300 scale-110 animate-pulse'
              : isProcessing()
              ? 'bg-yellow-500 border-yellow-300'
              : 'bg-blue-500 border-blue-300 hover:bg-blue-600 hover:scale-105'
            }
            ${isProcessing() ? 'cursor-wait' : 'cursor-pointer'}
          `}
        >
          {isProcessing() ? (
            <div class="animate-spin w-6 h-6 border-2 border-white border-t-transparent rounded-full"></div>
          ) : (
            <svg class="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 20 20">
              <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
            </svg>
          )}
        </button>

        {/* ç‹€æ…‹é¡¯ç¤º */}
        <div class="text-center">
          {isRecording() && (
            <div class="text-red-600 text-sm font-medium animate-pulse">
              ğŸ”´ éŒ„éŸ³ä¸­...
            </div>
          )}
          {isProcessing() && (
            <div class="text-yellow-600 text-sm font-medium">
              âš¡ è™•ç†ä¸­...
            </div>
          )}
          {!isRecording() && !isProcessing() && (
            <div class="text-gray-600 text-sm">
              ğŸ¤ æŒ‰ä½èªªè©±
            </div>
          )}
        </div>

        {/* æœ€å¾Œè½‰éŒ„çµæœ */}
        {lastTranscription() && (
          <div class="bg-white/90 backdrop-blur-sm rounded-lg shadow-lg p-3 max-w-xs">
            <div class="text-xs text-gray-500 mb-1">æœ€å¾ŒæŒ‡ä»¤ï¼š</div>
            <div class="text-sm text-gray-800">"{lastTranscription()}"</div>
          </div>
        )}

        {/* éŒ¯èª¤è¨Šæ¯ */}
        {error() && (
          <div class="bg-red-50/90 backdrop-blur-sm rounded-lg shadow-lg p-3 max-w-xs">
            <div class="text-xs text-red-500 mb-1">éŒ¯èª¤ï¼š</div>
            <div class="text-sm text-red-700">{error()}</div>
            <button
              onClick={() => setError('')}
              class="text-xs text-red-500 underline mt-1"
            >
              æ¸…é™¤
            </button>
          </div>
        )}

      </div>
    </div>
  );
};

export default VoiceControl;
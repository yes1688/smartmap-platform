import { Component, createSignal, onMount, onCleanup } from 'solid-js';
import { CONFIG } from '@/config';
import { gameStore, gameActions } from '@/stores/gameStore';

interface SpeechEarVoiceOrbProps {
  onMovementResponse?: (result: any) => void;
}

interface BrowserInfo {
  name: string;
  mimeType: string;
  ext: string;
  isSupported: boolean;
  webCodecsSupported?: boolean;
  recordingMethod?: 'webcodecs' | 'mediarecorder';
}

interface WebCodecsInfo {
  audioEncoder: boolean;
  audioDecoder: boolean;
  opusSupported: boolean;
  fullSupported: boolean;
}

export const SpeechEarVoiceOrb: Component<SpeechEarVoiceOrbProps> = (props) => {
  const [isRecording, setIsRecording] = createSignal(false);
  const [isProcessing, setIsProcessing] = createSignal(false);
  const [previewText, setPreviewText] = createSignal('');
  const [dynamicText, setDynamicText] = createSignal('');
  const [isActive, setIsActive] = createSignal(false);

  let mediaRecorder: MediaRecorder | null = null;
  let audioEncoder: AudioEncoder | null = null;
  let audioChunks: Blob[] = [];
  let audioPackets: Uint8Array[] = [];
  let recordingStartTime: number = 0;
  let dynamicTextInterval: number | null = null;

  // WebCodecs æ”¯æ´æª¢æ¸¬ - ä¾†è‡ª Speech Ear
  const detectWebCodecsSupport = (): WebCodecsInfo => {
    const hasAudioEncoder = typeof AudioEncoder !== 'undefined';
    const hasAudioDecoder = typeof AudioDecoder !== 'undefined';

    let opusSupported = false;
    if (hasAudioEncoder) {
      try {
        const testConfig = {
          codec: 'opus',
          sampleRate: 48000,
          numberOfChannels: 1,
          bitrate: 128000
        };
        try {
          const testEncoder = new AudioEncoder({
            output: () => {},
            error: () => {}
          });
          testEncoder.configure(testConfig);
          testEncoder.close();
          opusSupported = true;
        } catch {
          opusSupported = false;
        }
      } catch (e) {
        console.warn('WebCodecs OPUS æ”¯æ´æª¢æ¸¬å¤±æ•—:', e);
        opusSupported = false;
      }
    }

    const fullSupported = hasAudioEncoder && hasAudioDecoder && opusSupported;

    return {
      audioEncoder: hasAudioEncoder,
      audioDecoder: hasAudioDecoder,
      opusSupported: opusSupported,
      fullSupported: fullSupported
    };
  };

  // æª¢æ¸¬ç€è¦½å™¨å’Œæ”¯æ´çš„æ ¼å¼ - ä¾†è‡ª Speech Ear å¯¦è­‰å¯¦ç¾
  const detectBrowser = (): BrowserInfo => {
    const ua = navigator.userAgent;
    const webCodecs = detectWebCodecsSupport();

    if (ua.includes('Chrome') && !ua.includes('Edge')) {
      const mimeType = 'audio/webm;codecs=opus';
      return {
        name: 'Chrome',
        mimeType,
        ext: 'webm',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Edge')) {
      const mimeType = 'audio/webm;codecs=opus';
      return {
        name: 'Edge',
        mimeType,
        ext: 'webm',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Firefox')) {
      const mimeType = 'audio/ogg;codecs=opus';
      return {
        name: 'Firefox',
        mimeType,
        ext: 'ogg',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    } else if (ua.includes('Safari')) {
      const mimeType = 'audio/mp4';
      return {
        name: 'Safari',
        mimeType,
        ext: 'mp4',
        isSupported: MediaRecorder.isTypeSupported(mimeType),
        webCodecsSupported: webCodecs.fullSupported,
        recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
      };
    }

    const fallbackMime = 'audio/webm';
    return {
      name: 'Unknown',
      mimeType: fallbackMime,
      ext: 'webm',
      isSupported: MediaRecorder.isTypeSupported(fallbackMime),
      webCodecsSupported: webCodecs.fullSupported,
      recordingMethod: webCodecs.fullSupported ? 'webcodecs' : 'mediarecorder'
    };
  };

  // å‹•æ…‹æ–‡å­—æ•ˆæœ
  const startDynamicTextEffect = () => {
    const phrases = [
      'ğŸ¤ è†è½ä¸­...',
      'ğŸ‘‚ æ­£åœ¨è­˜åˆ¥...',
      'ğŸ§  ç†è§£èªéŸ³...',
      'ğŸ’­ åˆ†æèªæ„...',
      'ğŸ” è™•ç†æŒ‡ä»¤...',
      'âš¡ æº–å‚™å›æ‡‰...'
    ];

    let currentIndex = 0;

    dynamicTextInterval = setInterval(() => {
      setDynamicText(phrases[currentIndex]);
      currentIndex = (currentIndex + 1) % phrases.length;
    }, 800) as any;
  };

  const stopDynamicTextEffect = () => {
    if (dynamicTextInterval) {
      clearInterval(dynamicTextInterval);
      dynamicTextInterval = null;
    }
    setDynamicText('');
  };

  // èªéŸ³è­˜åˆ¥ç³»çµ±åˆå§‹åŒ–
  onMount(() => {
    console.log('ğŸš€ Speech Ear èªéŸ³çƒåˆå§‹åŒ–...');
    const browser = detectBrowser();
    const webCodecs = detectWebCodecsSupport();

    console.log('ğŸŒ æª¢æ¸¬åˆ°ç€è¦½å™¨:', browser);
    console.log('ğŸš€ WebCodecs æ”¯æ´:', browser.webCodecsSupported);
    console.log('ğŸ¤ éŒ„éŸ³æ–¹å¼:', browser.recordingMethod);
    console.log('ğŸ“Š WebCodecs è©³ç´°æ”¯æ´:', webCodecs);
  });

  // é–‹å§‹éŒ„éŸ³
  const startRecording = async () => {
    console.log('ğŸ¤ é–‹å§‹ Speech Ear èªéŸ³éŒ„éŸ³...');

    try {
      setIsRecording(true);
      setIsActive(true);
      setPreviewText('ğŸ¤ è‡ªä¸»èªéŸ³è­˜åˆ¥ä¸­...');

      // å•Ÿå‹•å‹•æ…‹æ–‡å­—æ•ˆæœ
      startDynamicTextEffect();

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        const trackSettings = audioTrack.getSettings();
        console.log('ğŸ” éŸ³é »é…ç½®:', trackSettings);
      }

      const browser = detectBrowser();

      if (!browser.isSupported) {
        throw new Error(`ç€è¦½å™¨ ${browser.name} ä¸æ”¯æ´éŸ³é »æ ¼å¼ ${browser.mimeType}`);
      }

      if (browser.recordingMethod === 'webcodecs' && browser.webCodecsSupported) {
        console.log('ğŸš€ ä½¿ç”¨ WebCodecs ç¡¬é«”åŠ é€ŸéŒ„éŸ³');
        await startWebCodecsRecording(stream);
      } else {
        console.log('ğŸ“¼ ä½¿ç”¨ MediaRecorder ç›¸å®¹æ¨¡å¼éŒ„éŸ³');
        await startMediaRecorderRecording(stream);
      }

      recordingStartTime = Date.now();

    } catch (err) {
      console.error('âŒ Speech Ear éŒ„éŸ³å¤±æ•—:', err);
      setPreviewText('âŒ éœ€è¦éº¥å…‹é¢¨æ¬Šé™');
      setIsRecording(false);
      setTimeout(() => setIsActive(false), 2000);
    }
  };

  // WebCodecs éŒ„éŸ³å¯¦ç¾
  const startWebCodecsRecording = async (stream: MediaStream) => {
    console.log('ğŸš€ å•Ÿå‹• WebCodecs ç¡¬é«”åŠ é€ŸéŒ„éŸ³');

    audioPackets = [];

    try {
      audioEncoder = new AudioEncoder({
        output: (chunk, metadata) => {
          console.log(`ğŸµ WebCodecs åŒ…è¼¸å‡º: ${chunk.byteLength} bytes`);
          const packetData = new Uint8Array(chunk.byteLength);
          chunk.copyTo(packetData);
          audioPackets.push(packetData);
        },
        error: (error) => {
          console.error('ğŸš¨ WebCodecs ç·¨ç¢¼éŒ¯èª¤:', error);
          setPreviewText(`âŒ ç·¨ç¢¼å¤±æ•—: ${error.message}`);
        }
      });

      const optimizedEncoderConfig = {
        codec: 'opus',
        sampleRate: 48000,
        numberOfChannels: 1,
        bitrate: 96000,
      };

      audioEncoder.configure(optimizedEncoderConfig);

      const track = stream.getAudioTracks()[0];
      const processor = new MediaStreamTrackProcessor({ track });
      const reader = processor.readable.getReader();

      const processAudioFrames = async () => {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          if (audioEncoder && audioEncoder.state === 'configured') {
            try {
              audioEncoder.encode(value);
            } catch (err) {
              console.error('ğŸš¨ éŸ³é »å¹€ç·¨ç¢¼å¤±æ•—:', err);
            }
          }
          value.close();
        }
      };

      processAudioFrames().catch(err => {
        console.error('ğŸš¨ éŸ³é »è™•ç†æµç¨‹éŒ¯èª¤:', err);
        setPreviewText(`âŒ éŸ³é »è™•ç†å¤±æ•—: ${err.message}`);
      });

      console.log('âœ… WebCodecs éŒ„éŸ³å·²å•Ÿå‹•');

    } catch (error) {
      console.error('ğŸš¨ WebCodecs åˆå§‹åŒ–å¤±æ•—:', error);
      setPreviewText(`âŒ WebCodecs åˆå§‹åŒ–å¤±æ•—: ${error.message}`);
    }
  };

  // MediaRecorder éŒ„éŸ³å¯¦ç¾
  const startMediaRecorderRecording = async (stream: MediaStream) => {
    console.log('ğŸ“¼ å•Ÿå‹• MediaRecorder ç›¸å®¹æ¨¡å¼éŒ„éŸ³');

    const browser = detectBrowser();
    const mimeType = browser.mimeType;

    mediaRecorder = new MediaRecorder(stream, {
      mimeType,
      audioBitsPerSecond: 64000
    });

    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: mimeType });
      console.log(`âœ… MediaRecorder éŒ„éŸ³å®Œæˆ - æ ¼å¼: ${mimeType}, å¤§å°: ${audioBlob.size} bytes`);
      stream.getTracks().forEach(track => track.stop());
      await transcribeAudio(audioBlob);
    };

    mediaRecorder.start();
    console.log('âœ… MediaRecorder éŒ„éŸ³å·²å•Ÿå‹•');
  };

  // åœæ­¢éŒ„éŸ³
  const stopRecording = () => {
    console.log('ğŸ›‘ åœæ­¢ Speech Ear èªéŸ³è­˜åˆ¥...');

    setIsRecording(false);

    // åœæ­¢å‹•æ…‹æ–‡å­—æ•ˆæœ
    stopDynamicTextEffect();

    const browser = detectBrowser();

    if (browser.recordingMethod === 'webcodecs' && audioEncoder) {
      console.log('ğŸ›‘ åœæ­¢ WebCodecs éŒ„éŸ³');
      try {
        audioEncoder.flush();
        audioEncoder.close();
        audioEncoder = null;

        if (audioPackets.length > 0) {
          const packetsData = {
            format: 'webcodecs_opus_packets',
            packet_count: audioPackets.length,
            packets: audioPackets.map(packet => Array.from(packet))
          };

          const jsonBlob = new Blob([JSON.stringify(packetsData)], { type: 'application/json' });
          console.log(`âœ… WebCodecs éŒ„éŸ³å®Œæˆ - åŒ…æ•¸é‡: ${audioPackets.length}, JSON å¤§å°: ${jsonBlob.size} bytes`);
          transcribeAudio(jsonBlob);
        } else {
          console.warn('âš ï¸ WebCodecs éŒ„éŸ³æ²’æœ‰æ”¶é›†åˆ°éŸ³é »åŒ…');
          setPreviewText('âŒ éŒ„éŸ³å¤±æ•—ï¼šæ²’æœ‰éŸ³é »æ•¸æ“š');
        }

      } catch (error) {
        console.error('ğŸš¨ WebCodecs åœæ­¢éŒ„éŸ³æ™‚å‡ºéŒ¯:', error);
        setPreviewText('âŒ åœæ­¢éŒ„éŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤');
      }

    } else if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ›‘ åœæ­¢ MediaRecorder éŒ„éŸ³');
      mediaRecorder.stop();
    }

    setIsProcessing(true);
    setTimeout(() => setIsActive(false), 2000);
  };

  // Speech Ear API èªéŸ³è½‰æ–‡å­—
  const transcribeAudio = async (audioBlob: Blob) => {
    console.log('ğŸ¯ Speech Ear èªéŸ³è½‰æ–‡å­—...');
    try {
      const recordingDuration = Date.now() - recordingStartTime;
      console.log('â±ï¸ éŒ„éŸ³æ™‚é•·:', recordingDuration, 'ms');

      if (recordingDuration < 500) {
        setPreviewText('âŒ éŒ„éŸ³æ™‚é–“å¤ªçŸ­');
        return;
      }

      if (audioBlob.size < 100) {
        setPreviewText('âŒ éŸ³é »æ•¸æ“šå¤ªå°');
        return;
      }

      const formData = new FormData();
      const browser = detectBrowser();

      if (audioBlob.type === 'application/json' && browser.recordingMethod === 'webcodecs') {
        const fileName = 'webcodecs-packets.json';
        formData.append('audio_packets', audioBlob, fileName);
        console.log(`ğŸš€ WebCodecs ç¨ç«‹åŒ…ä¸Šå‚³ - ${fileName}, ${audioBlob.size} bytes`);
      } else {
        const fileName = `recording.${browser.ext}`;
        formData.append('audio', audioBlob, fileName);
        console.log(`ğŸ“¼ MediaRecorder ä¸Šå‚³ - ${fileName}, ${audioBlob.size} bytes`);
      }

      const speechEarUrl = import.meta.env.VITE_SPEECH_EAR_URL || 'http://localhost:3001';
      console.log('ğŸŒ Speech Ear URL:', speechEarUrl);

      const response = await fetch(`${speechEarUrl}/upload`, {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.log('ğŸš¨ Speech Ear API éŒ¯èª¤:', errorText);
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('âœ… Speech Ear èªéŸ³è½‰æ–‡å­—çµæœ:', result);

      const transcription = result.transcript || result.full_transcript || result.text;
      if (transcription && transcription.trim()) {
        const finalTranscription = transcription.trim();
        setPreviewText(`ğŸ’¬ ${finalTranscription}`);

        await processVoiceCommand(finalTranscription);

        console.log('ğŸ¯ èªéŸ³æŒ‡ä»¤:', finalTranscription);
        console.log('âš¡ è™•ç†æ™‚é–“:', result.processing_time_ms, 'ms');
        console.log('ğŸ¯ ä¿¡å¿ƒåº¦:', result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'æœªçŸ¥');
      } else {
        setPreviewText('âŒ æœªèƒ½è­˜åˆ¥èªéŸ³å…§å®¹');
      }

    } catch (err) {
      console.error('âŒ Speech Ear èªéŸ³è½‰æ–‡å­—å¤±æ•—:', err);
      setPreviewText('âŒ èªéŸ³è™•ç†å¤±æ•—ï¼š' + (err as Error).message);
    } finally {
      setIsProcessing(false);
    }
  };

  // è™•ç†èªéŸ³æŒ‡ä»¤
  const processVoiceCommand = async (text: string) => {
    if (!text.trim()) return;

    try {
      const response = await fetch(`${CONFIG.api.baseUrl}${CONFIG.api.endpoints.aiChat}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          playerId: gameStore.currentPlayer?.id || 'default_player',
          message: text,
          context: 'Speech Ear èªéŸ³æ§åˆ¶'
        }),
      });

      if (response.ok) {
        const data = await response.json();

        if (data.type === 'movement' && data.data?.success) {
          if (data.data.newPosition) {
            gameActions.setPlayerPosition(
              data.data.newPosition.latitude,
              data.data.newPosition.longitude
            );
          }

          if (props.onMovementResponse) {
            props.onMovementResponse(data.data);
          }

          setPreviewText('âœ… ç§»å‹•æˆåŠŸï¼');
        } else {
          setPreviewText('âŒ æŒ‡ä»¤ç„¡æ³•åŸ·è¡Œ');
        }
      }
    } catch (error) {
      console.error('Speech Ear èªéŸ³æŒ‡ä»¤è™•ç†å¤±æ•—:', error);
      setPreviewText('âŒ é€£æ¥å¤±æ•—');
    }
  };

  // å¿«æ·éµæ”¯æŒ
  onMount(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.code === 'Space' && !isRecording()) {
        e.preventDefault();
        startRecording();
      }
    };

    const handleKeyUp = (e: KeyboardEvent) => {
      if (e.code === 'Space' && isRecording()) {
        e.preventDefault();
        stopRecording();
      }
    };

    document.addEventListener('keydown', handleKeyDown);
    document.addEventListener('keyup', handleKeyUp);

    onCleanup(() => {
      document.removeEventListener('keydown', handleKeyDown);
      document.removeEventListener('keyup', handleKeyUp);

      // æ¸…ç†å‹•æ…‹æ–‡å­—æ•ˆæœ
      stopDynamicTextEffect();

      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      }
      if (audioEncoder) {
        audioEncoder.close();
      }
    });
  });

  return (
    <div class="fixed bottom-6 right-6 z-50 flex flex-col items-end gap-2">
      {/* èªéŸ³é è¦½æ°£æ³¡ */}
      {(isActive() && (previewText() || dynamicText())) && (
        <div class="bg-black/80 backdrop-blur-md text-white px-4 py-2 rounded-full text-sm max-w-xs animate-in fade-in slide-in-from-bottom-2 duration-300">
          {/* å‹•æ…‹æ–‡å­—æ•ˆæœ - éŒ„éŸ³æ™‚é¡¯ç¤º */}
          {isRecording() && dynamicText() ? (
            <div class="animate-pulse">
              {dynamicText()}
            </div>
          ) : (
            previewText()
          )}
        </div>
      )}

      {/* Speech Ear èªéŸ³çƒ */}
      <div class="relative">
        <button
          onMouseDown={startRecording}
          onMouseUp={stopRecording}
          onTouchStart={startRecording}
          onTouchEnd={stopRecording}
          class={`group relative w-16 h-16 rounded-full transition-all duration-300 transform hover:scale-110 active:scale-95 ${
            isRecording()
              ? 'bg-gradient-to-br from-green-500 to-emerald-600 shadow-2xl animate-pulse'
              : isProcessing()
              ? 'bg-gradient-to-br from-blue-500 to-indigo-600 shadow-xl'
              : 'bg-gradient-to-br from-purple-500 to-violet-600 shadow-lg hover:shadow-xl'
          }`}
          style={{
            "backdrop-filter": "blur(20px)",
            "border": "1px solid rgba(255, 255, 255, 0.2)"
          }}
        >
          {/* å‹•æ…‹æ³¢ç´‹æ•ˆæœ */}
          {isRecording() && (
            <>
              <div class="absolute inset-0 rounded-full bg-green-500/30 animate-ping"></div>
              <div class="absolute inset-0 rounded-full bg-green-500/20 animate-ping animation-delay-75"></div>
            </>
          )}

          {/* ä¸­å¿ƒåœ–æ¨™ */}
          <div class="relative z-10 w-full h-full flex items-center justify-center">
            {isProcessing() ? (
              <svg class="w-8 h-8 text-white animate-spin" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
            ) : (
              <div class="flex flex-col items-center">
                <svg
                  class={`w-6 h-6 text-white transition-transform duration-300 ${isRecording() ? 'scale-125' : 'group-hover:scale-110'}`}
                  fill="currentColor"
                  viewBox="0 0 24 24"
                >
                  <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
                  <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
                  <line x1="12" y1="19" x2="12" y2="23"/>
                  <line x1="8" y1="23" x2="16" y2="23"/>
                </svg>
                <div class="text-xs text-white mt-1 font-semibold">ğŸ </div>
              </div>
            )}
          </div>

          {/* ç»ç’ƒåå…‰æ•ˆæœ */}
          <div class="absolute inset-0 rounded-full bg-gradient-to-tr from-white/20 via-white/10 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div>
        </button>

        {/* æ“ä½œæç¤º */}
        {!isActive() && (
          <div class="absolute -bottom-8 right-0 text-xs text-gray-600 opacity-0 group-hover:opacity-100 transition-opacity duration-300 whitespace-nowrap">
            Speech Ear èªéŸ³ / ç©ºæ ¼éµ
          </div>
        )}
      </div>
    </div>
  );
};

export default SpeechEarVoiceOrb;